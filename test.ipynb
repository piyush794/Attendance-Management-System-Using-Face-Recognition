{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-18T12:18:15.319566Z",
     "start_time": "2024-11-18T12:18:12.774547Z"
    }
   },
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy\n",
    "import os\n",
    "import torchvision\n",
    "import argparse\n",
    "import time \n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T12:08:38.889125Z",
     "start_time": "2024-11-18T12:08:38.885137Z"
    }
   },
   "cell_type": "code",
   "source": "path=\"E:/Attendance_Management_System/Training_images\"",
   "id": "d68122a950add464",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T12:08:41.292065Z",
     "start_time": "2024-11-18T12:08:41.258451Z"
    }
   },
   "cell_type": "code",
   "source": [
    "parser = argparse.ArgumentParser(description='Code for Cascade Classifier tutorial.')\n",
    "parser.add_argument('--face_cascade', help='Path to face cascade.', default='haarcascade_frontalface_alt.xml')\n",
    "parser.add_argument('--eyes_cascade', help='Path to eyes cascade.', default='haarcascade_eye_tree_eyeglasses.xml')\n",
    "parser.add_argument('--camera', help='Camera divide number.', type=int, default=0)\n",
    "\n",
    "\n",
    "args, unknown = parser.parse_known_args()\n",
    " \n",
    "face_cascade_name = args.face_cascade\n",
    "eyes_cascade_name = args.eyes_cascade\n",
    " \n",
    "face_cascade = cv2.CascadeClassifier()\n",
    "eyes_cascade = cv2.CascadeClassifier()\n",
    " \n",
    "#-- 1. Load the cascades\n",
    "if not face_cascade.load(cv2.samples.findFile(face_cascade_name)):\n",
    "    print('--(!)Error loading face cascade')\n",
    "    exit(0)\n",
    "if not eyes_cascade.load(cv2.samples.findFile(eyes_cascade_name)):\n",
    "    print('--(!)Error loading eyes cascade')\n",
    "    exit(0)"
   ],
   "id": "7752f55b6156cacf",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T12:08:43.051641Z",
     "start_time": "2024-11-18T12:08:43.044920Z"
    }
   },
   "cell_type": "code",
   "source": "unknown",
   "id": "8d3eef0453d476cb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-f',\n",
       " 'C:\\\\Users\\\\ASUS\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-caca678f-08ce-425e-94b6-0f85785f94c5.json']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T12:16:23.654227Z",
     "start_time": "2024-11-18T12:16:23.199221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "count=0\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Cannot open camera')\n",
    "    exit()\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    time.sleep(1)\n",
    "    # if frame is read correctly ret is true \n",
    "    if not ret:\n",
    "         print(\"Can't receive frame (stream end?). Exiting ...\")\n",
    "         break\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    \n",
    "    ##using Cascade Classifier to detect eyes and images\n",
    "    faces = face_cascade.detectMultiScale(gray)\n",
    "    for (x,y,w,h) in faces:\n",
    "        center = (x + w//1.8, y + h//1.8)\n",
    "        frame = cv2.ellipse(gray, center, (w//2, h//2), 0, 0, 360, (255, 0, 255), 4)\n",
    " \n",
    "        faceROI = gray[y:y+h,x:x+w]\n",
    "        \n",
    "        #-- In each face, detect eyes\n",
    "        eyes = eyes_cascade.detectMultiScale(faceROI)\n",
    "        for (x2,y2,w2,h2) in eyes:\n",
    "            eye_center = (x + x2 + w2//2, y + y2 + h2//2)\n",
    "            radius = int(round((w2 + h2)*0.25))\n",
    "            frame = cv2.circle(gray, eye_center, radius, (255, 0, 0 ), 4)\n",
    "    cv2.imshow('frame', frame)\n",
    "    \n",
    "    \n",
    "    while count<70:\n",
    "        \n",
    "        time.sleep(2)\n",
    "        cv2.imwrite(os.path.join(path,'frame'+str(count)+'.png'), gray)\n",
    "        count+=1\n",
    "        print(\"Image saved: \",count)\n",
    "        \n",
    "        \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "cfdb26d169d3ec44",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m cap \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mVideoCapture(\u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m      2\u001B[0m count\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m\n\u001B[0;32m      3\u001B[0m detector \u001B[38;5;241m=\u001B[39m cv2\u001B[38;5;241m.\u001B[39mCascadeClassifier(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhaarcascade_frontalface_default.xml\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T11:24:16.884529Z",
     "start_time": "2024-11-18T11:24:16.882279Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "e0301ba976c49c3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T11:24:22.657680Z",
     "start_time": "2024-11-18T11:24:22.654927Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "8f7bf9a5f65e1fa3",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T11:24:26.292342Z",
     "start_time": "2024-11-18T11:24:26.289286Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "4b418b2e92e43ff9",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T11:24:28.034456Z",
     "start_time": "2024-11-18T11:24:28.015178Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a28bc0f7e0742aa0",
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'Image'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[33], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m loc\u001B[38;5;241m=\u001B[39mcv2\u001B[38;5;241m.\u001B[39mImage(path)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'cv2' has no attribute 'Image'"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:35:24.461860Z",
     "start_time": "2024-11-18T10:35:01.845806Z"
    }
   },
   "cell_type": "code",
   "source": [
    "record = cv2.VideoCapture(0)\n",
    "path=\"E://Attendance_Management_System//face_Detection\"\n",
    "detector = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "sample_no =0\n",
    "while True:\n",
    "    ret, frame = record.read()\n",
    "    time.sleep(1/20)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    faces = detector.detectMultiScale(gray, 1.3, 5)\n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        sample_no = sample_no + 1\n",
    "        cv2.imwrite(os.path.join(path,\"Training_set/\"+str(sample_no)+\".jpg\"), frame[y:y+h, x:x+w])\n",
    "    cv2.imshow(\"webcam\",frame)\n",
    "    if cv2.waitKey(1)& 0xFF==ord(\"x\"):\n",
    "        break\n",
    "    elif sample_no>80:\n",
    "        break\n",
    "record.release()\n",
    "cv2.destroyAllWindows()\n",
    "  "
   ],
   "id": "6d0ec8ade1a6eae",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:07:04.328143Z",
     "start_time": "2024-11-18T10:07:04.295239Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "616cdc2402348a46",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhel\u001B[39m\u001B[38;5;124m\"\u001B[39m ,frame)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'frame' is not defined"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:10:40.957052Z",
     "start_time": "2024-11-18T10:10:40.953844Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "ee39b9a0b804ef76",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "e4d11fde9d6fce08"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T10:53:08.412330Z",
     "start_time": "2024-11-18T10:53:08.341903Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "\n",
    "capture = cv2.VideoCapture('../data/drop.avi')\n",
    "frame_count = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print('Frame count:', frame_count)\n",
    "\n",
    "print('Position:', int(capture.get(cv2.CAP_PROP_POS_FRAMES)))\n",
    "_, frame = capture.read()\n",
    "cv2.imshow('frame0', frame)\n",
    "\n",
    "print('Position:', int(capture.get(cv2.CAP_PROP_POS_FRAMES)))\n",
    "_, frame = capture.read()\n",
    "cv2.imshow('frame1', frame)\n",
    "\n",
    "capture.set(cv2.CAP_PROP_POS_FRAMES, 100)\n",
    "print('Position:', int(capture.get(cv2.CAP_PROP_POS_FRAMES)))\n",
    "_, frame = capture.read()\n",
    "cv2.imshow('frame100', frame)\n",
    "    \n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "db2b718015784412",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame count: 0\n",
      "Position: 0\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31merror\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[22], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPosition:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mint\u001B[39m(capture\u001B[38;5;241m.\u001B[39mget(cv2\u001B[38;5;241m.\u001B[39mCAP_PROP_POS_FRAMES)))\n\u001B[0;32m      8\u001B[0m _, frame \u001B[38;5;241m=\u001B[39m capture\u001B[38;5;241m.\u001B[39mread()\n\u001B[1;32m----> 9\u001B[0m cv2\u001B[38;5;241m.\u001B[39mimshow(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mframe0\u001B[39m\u001B[38;5;124m'\u001B[39m, frame)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPosition:\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mint\u001B[39m(capture\u001B[38;5;241m.\u001B[39mget(cv2\u001B[38;5;241m.\u001B[39mCAP_PROP_POS_FRAMES)))\n\u001B[0;32m     12\u001B[0m _, frame \u001B[38;5;241m=\u001B[39m capture\u001B[38;5;241m.\u001B[39mread()\n",
      "\u001B[1;31merror\u001B[0m: OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:973: error: (-215:Assertion failed) size.width>0 && size.height>0 in function 'cv::imshow'\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3a88e790e9387dd1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T12:05:38.147560Z",
     "start_time": "2024-11-18T12:05:38.143398Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "291e6d9d822869d8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-18T12:05:21.384430Z",
     "start_time": "2024-11-18T12:05:21.381667Z"
    }
   },
   "cell_type": "code",
   "source": "\n",
   "id": "c624bd0b9907d1f5",
   "outputs": [],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bfbae209ec3e977e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
